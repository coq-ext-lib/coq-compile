\documentclass{article}

\usepackage{listings}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{color}
\usepackage{amsmath}
\usepackage{lstcoq}

\lstset{mathescape=true,basicstyle=\small\ttfamily,frame=lines,language=coq}

\title{cs252r: Coq Compilation \& Runtime}
\author{Daniel Huang \and Gregory Malecha \and Scott Moore}

\newcommand{\todo}[1]{\textcolor{red}{#1}}

\begin{document}

\maketitle

Our project expanded to encompass 7 main tasks. The foremost of those is to have a working compiler, i.e. we placed a large emphasis on generating runnable LLVM code. This resulted in seven pieces:

\begin{description}
\item[Driver \& Test Tools]
We built (and refactored the previous driver) to run our compiler with a number of options, e.g. outputting intermediate representations, running and not running optimizations, etc. This makes the compiler externally usuable and facilitates testing. In addition, we have extracted an interpreter that can be used to test optimizations. (Section~\ref{sec:driver})
\item[Refactored ILs]
Our initial tasks centered around refactoring the intermediate language. In the Cps representation, we syntactically distinguished continuations and extended the IL to support monadic operations in a world-passing style. In addition, we introduced a new intermediate language (Low) that separates the details of this Cps representation from the details of code-generation. (Section~\ref{sec:il})
\item[Input/Output]
To support debugging, our runtime supports output operations to print ascii characters. These can be composed in Coq to implement displaying strings and other interesting data types. These operations are accessed via parameters exposed in Coq and compiled to special routines by our compiler. (Section~\ref{sec:io})
\item[Garbage Collection]
GC-based functional languages require a reasonable garbage collector and runtime environment. We developed a Chaney-copying collector built using LLVM's GC intrinsics. (Section~\ref{sec:gc})
\item[Abstract Interpretation] 
We built an abstract interpreter for our Cps representation to facilitate more interesting analyses. We have instantiated it to do a standard control-flow analysis though it is phrased in a way that enables it to be used for a variety of analyses. (Section~\ref{sec:abstract-interp})
\item[Destructive Updates]
A major issue with functional languages is the creation of temporary data structures. For example, threading a state through computations in the state monad. To avoid the cost of many small allocations (primarily to ease the GC burden since allocation is reasonable fast) we have an optimization that uses the result of static analysis to reuse dead memory. (Section~\ref{sec:destructive-updates})
\item[Contification]
Distinguished continutations are handled efficiently by our compiler enabling us to stack allocate data associated with continuations. An optimization works on demoting first-class functions into continuations to increase the applicability of this process. (Section~\ref{sec:contification})
\end{description}

\section{The Driver}
\label{sec:driver}

The driver is built from using standard Coq extraction to ML to provide an efficient way to run the top-level compiler. For example, we can compile and run the standard HelloWorld program using the following command line:

\begin{verbatim}
$ ./Wrapper.byte - ...
$ ./helloworld.native
Hello World!
\end{verbatim}

In in addition to the driver, we also have an interpreter for our CpsK language. The semantics are faithful to the real semantics with the exception that there is no semantic distinction between continuations and closures. The former should be not be allowed to escape. We rely on our syntactic distinction to enforce this though it may be possible to break this requirement. A run of the interpreter is shown in Figure~\ref{fig:interp}.

\begin{figure}
\centering
\vspace{10pt}
\begin{minipage}[t]{.55\textwidth}
\begin{verbatim}
$./Extraction/CpsKInterpTL.byte -n 1000 -i Even 
-t main -o even.res
Input: Even
Term: main
Output: even.res
----

SUCCESS!!!!!!!!!!!!!!!!!!!!!!!!!!!
$
$ cat even.res
Con(True)
\end{verbatim}
\end{minipage}
\begin{minipage}[t]{.3\textwidth}
\begin{lstlisting}
Fixpoint even (n:nat) : bool :=
  match n with
    | O => true
    | S n => odd n
  end
with odd (n:nat) : bool :=
  match n with
    | O => false
    | S n => even n
  end.

Definition main := even 10.
\end{lstlisting}
\end{minipage}
\caption{Example run of our extracted CpsK interpreter on the Coq program even (shown on right)}
\label{fig:interp}
\end{figure}

\section{Intermediate Languages}
\label{sec:il}

Our compiler is based on two core intermediate languages, CpsK and Low, shown in Listings~\ref{code:cpsk}~and~\ref{code:low}.

\paragraph{CpsK} We modified the Cps representation in two ways. First, we made continuations second class. This allows us to differentiate between functions and continuations, allowing a number of optimizations including stack allocation of continuations~\cite{kennedy07cps}. Second, we added a monadic bind operation that allows us pass an explicit world to model the side effects of IO operations.

\begin{figure}
\lstset{language=coq,caption={CpsK intermediate language},label={code:cpsk}, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
(** CpsK exp are a sequence of let-bindings that either terminate with a function application or fork using a switch into a tree of nested CpsK expressions. *)
Inductive exp : Type := 
| App_e : op -> list cont -> list op -> exp
| Let_e : decl -> exp -> exp
| Letrec_e : list decl -> exp -> exp
  (** Switch is only used on small integer values and unlike Match, doesn't do any pattern matching.  The optional expression at the end is a default in case none of the patterns matches the value. *)
| Switch_e : op -> list (pattern * exp) -> option exp -> exp
| Halt_e : op -> op -> exp
| AppK_e : cont -> list op -> exp
| LetK_e : list (cont * list var * exp) -> exp -> exp
with decl : Type := 
  (** let x := v *)
| Op_d : var -> op -> decl
  (** let x := p(v1,...,vn) *)
| Prim_d : var -> primop -> list op -> decl
  (** let f := fun (x1,...,xn) => e *)
| Fn_d : var -> list cont -> list var -> exp -> decl
  (** let (x,w') := m(w,v1,..,vn) => e *)
| Bind_d : var -> var -> mop -> list op -> decl.
\end{lstlisting}
\end{figure}

\paragraph{Low} The motivation for Low is to provide a higher-level, but imperative language to serve as an intermediate point between CpsK and LLVM. This means that the final code generation phase can focus more on the details of calling convention, allocation, and garbage collection while avoiding the need to do large transformations of the code. Low has several interesting design decisions:
\begin{description}
\lstset{language=low,caption={Low intermediate language},label={code:low}, basicstyle={\footnotesize\ttfamily}}
\item[Functional Blocks] Basic blocks in Low take two sets of parameters: \lstinline!inscope! and arguments. \lstinline!inscope! arguments are lexically in scope in all blocks that call this block. Arguments are used to specify arguments to continuations. This allows us to generate LLVM code for basic blocks independently of control flow and then generate phi nodes in a follow up pass.
\item[Continuation-passing style] While Low is an imperative language, it still encodes continuations at a high level. Function calls take lists of continuations as arguments. Continuations can either be local, compiled as basic blocks in the same function, or a parameter. In codegen, local continuations passed to calls are compiled to jumps following the call, and parameter continuations are compiled to return statements.
\lstset{language=cpsk,caption={Low intermediate language},label={code:low}, basicstyle={\footnotesize\ttfamily}}
\item[Explicit Memory Operations] The transformation from CpsK to Low replaces \lstinline!mkTuple! and projection with low-level memory operations \lstset{language=low,caption={Low intermediate language},label={code:low}, basicstyle={\footnotesize\ttfamily}} \lstinline!malloc!, \lstinline!alloc!, \lstinline!load!, and \lstinline!store!. Malloc and alloc are interesting because they support multiple allocations. This allows the code generator to lower recursive allocations to a single large allocation, eliminating the need for partial initialization to prevent garbage collection errors.
\end{description}

\begin{figure}
\lstset{language=coq,caption={Low intermediate language},label={code:low}, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
Inductive primtyp :=
| Int_t : primtyp
| Ptr_t : primtyp -> primtyp
| Struct_t : list primtyp -> primtyp.

Inductive instr :=
| Primop_i : var -> primop -> list op -> instr
| Alloca_i : list (var * primtyp) -> instr
| Malloc_i : list (var * primtyp) -> instr
(* Load_i(var,type,offset,ptr) => var = *((type* )(ptr+offset)) *)
| Load_i : var -> primtyp -> Z -> op -> instr
(* Store_i(type,value,offset,ptr) => *(ptr+offset) = value *)
| Store_i : primtyp -> op -> Z -> op -> instr
| Bind_i : var -> mop -> list op -> instr.

(* A function can be called with a list of continuations that were either passed as arguments (referred to by the index of the formal) or that were bound locally (referred to by the label of the generated code block and a list of arguments, which may include the return value). *)
Definition cont : Type := (nat + label)%type.

Inductive term :=
| Halt_tm : op -> term
| Call_tm : var -> op -> list op -> list (cont * list op) -> term
(* Return to a passed-in continuation *)
| Cont_tm : cont -> list op -> term
| Switch_tm : op -> list (pattern * label * list op) -> option (label * list op) -> term.

Record block := mk_block {
  b_args : list var;
  b_scope : list var;
  b_insns : list instr;
  b_term : term
}.

Record function := mk_function {
  f_name  : fname ;
  f_args  : list var ;
  f_conts : nat ;
  f_body  : alist label block ; 
  f_entry : label
}.

Record program := mk_program {
  p_topdecl : list function ;
  p_entry : fname
}.
\end{lstlisting}
\end{figure}

\section{Input/Output}
\label{sec:io}

The compiler provides a small runtime library that enables compilation of computations that perform I/O. These operations are exposed to Coq using a simple IO mond that supports the standard \verb!return! and \lstinline!bind! in addition to \lstinline!printChar : ascii -> IO unit!. Extraction rules are specified for these functions and, if the program is compiled with I/O support, these functions are included by the compiler, implemented directly in CpsK.

\lstinline!printChar! is a monadic operation in CpsK (used by \coqe{Bind_d}). It takes 2 arguments: the world (like all monadic operations) and a pointer to the ascii to print. This make code-generation easy because we can write the code to destructure the ascii in C, performing all the necessary bit-wise operations in C. The drawback to this implementation is that it requires allocation in order to invoke. For example, even if we are printing a constant, it is necessary to perform an allocation (which is something that LLVM can not optimize). 

An alternative formulation (actually our original) is to have \coqe{printChar} take 9 arguments for the world and the 8 bits of the \coqe{ascii}. This exposes more opportunities for our Coq-level optimization while making code generation only slightly more cumbersome. 

\section{Garbage Collection}
\label{sec:gc}

Our runtime supports three basic types: \emph{integers}, \emph{pointers}, and \emph{records}. Integers have a low-order bit of one and are used to encode both constructors and machine words, though our current front-end does not emit non-constructor integers. Pointers and integers are both stored in words large enough to encode a pointer on the target architecture, and can be distinguished by their low-order bit, since objects in the runtime are at least 4-byte aligned. A record is a sequence of $n > 1$ integers or pointers preceeded by a header word indicating the length of the record. The runtime does not permit pointers into the middle of objects. As a result, headers can be stored as an integer with no tag, eliminating additional arithmetic when indexing a record.

We implemented a semispace garbage collector based on Cheney's algorithm. The source code is given in Listing~\ref{code:forward}. The collector is similar to Appel's copying collector~\cite{Appel90aruntime}, but is simplified by our data representation. A brief description of the algorithm follows.

\paragraph{Finding stack roots} To find the local roots from which to traverse the reachable heap, we rely on LLVM's ``shadow stack'' plugin. We emit explicit stack allocations for all local variables that may point into the heap, and mark these as roots using the \lstinline!@llvm.gcroot! intrinsic. The shadow stack plugin emits additional code during function prologues and epilogues to construct a linked list of frame maps recording the addresses of the marked roots. This entry to this linked list is accessible to the garbage collector via a global variable. There are two advantages to recording roots dynamically this way: it is highly portable, and does not require writing low-level code to walk through stack frames. On the other hand, frame maps can be computed statically and generating the shadow stack has significant overhead.

Our generated code stores heap pointers into these stack slots immediately before function calls and invocations of the garbage collector, and reloads the possibly modified pointers afterwards. As an optimization, we only store and reload roots for live variables and set roots for dead variables to null.

\paragraph{Forwarding pointers} The core of Cheney's algorithm is a routine for \emph{forwarding} pointers---copying pointed-to objects into ``tospace'' and updating pointers to the new locations. \lstinline!forward(universal_t *objref)! takes as input a pointer to a word that may itself be a pointer into the heap. If the word is not a pointer into ``fromspace'', it doesn't need to be updated. If the word is a pointer into ``fromspace'', there are two possibilites:
\begin{enumerate}
\item The pointed-to object has not been copied to ``tospace''. The object is copied into the free space at the end of ``tospace''. In ``fromspace'', the header is replaced a tag denoting that the object has been copied. We use 0 because it is an invalid record length, and header tags never need to be differentiated from pointers. A forwarding pointer to the object's new location is overwritten in the first slot of the record.
\item The pointed-to object was already copied to ``tospace''. We detect an object has already been copied by looking for the forwarding pointer tag in the header, and then update the pointer being forwarded with the forwarding pointer we stored when copying the object.
\end{enumerate}
Cheney's algorithm copies the live heap in a breadth first search from the roots. First, the roots in the shadow stack are forwarded into ``tospace'' and then objects in ``tospace'' are traversed as a queue, forwarding any pointers encountered and copying reachable objects.

\paragraph{Memory protection} To catch garbage collection errors as quickly as possible, we read and write protect the unused semispace when not actively garbage collection. This was a key debugging technique for making sure stack roots were being updated correctly.

\paragraph{Allocation} We use a bump pointer allocator for speedy allocation. Because LLVM does not support pinning global values in registers, all functions we emit take a structure containing the current base and limit pointers as an argument, and return a structure that contains a new base and limit pointer and the functions actual return value. Because these structs are ``Plain Old Data'' types, LLVM will emit code that passes these values in registers whenever possible. This has the added advantage of allowing LLVM to spill the allocator registers when doing so would result in more efficient code.

\begin{figure}
\lstset{language=C,caption={Copying collector},label={code:forward}, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
void forward(universal_t *objref) {
  universal_t *ptr = *((universal_t **)objref);
  if (is_ptr(ptr) && (ptr >= curbot && ptr < curtop)) {
    /* ptr is a pointer to an object in fromspace */
    if (is_rec(ptr)) {
      /* Get a pointer to the header */
      universal_t *header = hdr(ptr);
      /* Retrieve the length of the record (plus one for the header) */
      universal_t len = rec_len(ptr) + 1;
      /* Copy the object starting at the header into tosapce */
      universal_t *i = header;;
      universal_t *j = endptr;
      while (len-- > 0) {
        *j++ = *i++;
      }
      /* Set the forwarding pointer in fromspace and update the record's tag */
      *ptr = (universal_t)(endptr + 1);
      *header = UINTPTR_MAX;
      /* Move the end of the queue forward */
      endptr = j;
    }
    /* ptr must be a forwarding pointer. It either already was, or we 
       forwarded it above. Update the objref to point to the new object */
    *objref = *((universal_t *)ptr);
  }
}

void visitGCRoot(void **root, const void *meta) {
  forward((universal_t *)root);
}

bumpptr_t coq_gc(void) {
  universal_t *tospace = (curbot == tobot) ? frombot : tobot;

  /* ... omitted memory protection code ... */

  /* initialize the queue in tospace */
  queueptr = (curbot == frombot) ? tobot : frombot;
  endptr = queueptr;

  /* Call forward on the roots */
  visitGCRoots(&visitGCRoot);

  /* iterate the worklist until we're done copying */
  while (queueptr < endptr) {
    universal_t *objref = queueptr+1;
    assert(is_rec(objref)); /* all heap allocations are records */
    queueptr += rec_len(objref) + 1;
    do {
      forward(objref++);
    } while (objref < queueptr);
  }

  /* ... omitted memory protection code ... */

  /* Swap spaces and return the new bump pointers */
  curbot = (curbot == frombot) ? tobot : frombot;
  curtop = (curtop == fromtop) ? totop : fromtop;

  assert(curbot <= endptr && endptr <= curtop);

  /* allocation starts at the end of the queue */
  return (bumpptr_t) { .base = endptr, .limit = curtop };
}
\end{lstlisting}
\end{figure}

\section{Abstract Interpretation}
\label{sec:abstract-interp}

We wrote an abstract interpreter for the CpsK language in the style of Van Horn~\cite{van2010abstracting}, i.e. the implementation is modeled after the implementation of the concrete interpreter. The abstract interpreter is parameterized over an abstract domain shown in Figure~\ref{fig:absinterp}. In addition, abstract values ($\hat{V}$) have abstract transfer functions for each of the primitive operations, e.g. tuple projection, closure creation, function call, etc.

\begin{figure}
\centering
\begin{minipage}[t]{.2\textwidth}
\begin{align*}
C: & \text{Context} \\
PP: & \text{Program point} \\
\hat{V}: & \text{Abstract values} \\
D: & \text{Domain}
\end{align*}
\end{minipage}
\hspace{20pt}
\begin{minipage}[t]{.43\textwidth}
\begin{lstlisting}
Class AbsDomain : Type :=
{ lookup  : C -> PP -> D -> V
; update  : C -> PP -> V -> D -> D
; joinA   : D -> D -> D
; bottomA : V 
; topA    : V 
; dom_leq : D -> D -> bool
}.
\end{lstlisting}
\end{minipage}
\caption{Select parameters of the abstract interpreter.}
\label{fig:absinterp}
\end{figure}

\begin{figure}
\begin{align*}
& p \in PP, i \in Z, c \in \text{str}, k \in \text{cont}, x \in \text{var}, e \in \text{exp}, \ell \in \text{loc} \\
C := & \;\; \text{unit} \\
PP := & \;\; \text{var} + \text{cont} \\
\hat{v} ::= & \;\; \texttt{Int}(i) \;\; | \;\; \texttt{Constructor}(c) \;\; | \;\; \texttt{Loc}(\ell) \;\; | \;\; \texttt{Closure}(p, \lambda \vec{k} \vec{x}. e) \\
\hat{V}::= & \;\; \texttt{Any} \;\; | \;\; [\hat{v}_1, \hdots, \hat{v}_n] \\
D: & \;\; \{{\tt env}: PP \rightarrow \hat{V} ; \;\;\; {\tt heap}: \text{loc} \rightarrow [\hat{V}_1, \hdots, \hat{V}_n] \}
\end{align*}
\caption{Instantiation of abstract domain for 0-CFA.}
\label{fig:cfa0}
\end{figure}
Figure~\ref{fig:cfa0} shows an instantiation of our abstract interpreter to perform a context-insensitive Control Flow Analysis (0-CFA). Program points are either variables or continuations since all results are named in Cps. Abstract locations are the variable names occurring in {\tt mkTuple} declarations. The domain $D$ is a record of an environment (mapping program points to abstract values) and heap (which maps abstract locations to lists of abstract values representing the pointwise components of the tuple). We did not put closures in the heap because our analysis is not context sensitive.

\section{Destructive Updates}
\label{sec:destructive-updates}

The main idea of a destructive update is to reuse previously allocated memory instead of allocating fresh space if we can prove that all pointers to the old memory are dead. One interesting application of this optimization is for programs that use the state monad. After an inlining pass inlines the definitions of bind to expose the state tuples explicitly, we can destructively update state that is threaded through the program instead of allocating new space for each bind. We based our optimization off the ideas described by Dimoulas and Wand in~\cite{dimoulas2009higher}, which presents an algorithm for detecting and transforming higher-order programs to use destructive updates. We summarize the optimization below.

\begin{itemize}
\item Perform control flow analysis ${\tt cfa} : {\rm CpsK.exp} \rightarrow (PP \rightarrow \mathcal{P}(\hat{V}))$ using abstract interpretation. 
\item Perform reachability analysis ${\tt reach} : (PP \rightarrow \mathcal{P}(\hat{V})) \rightarrow (PP \rightarrow {\rm set} \; PP)$ using the result of the CFA, to compute for each program point the set of program points that flow to it (i.e., transitive closure on the domain produced by CFA).
\item Perform liveness analysis ${\tt live} : {\rm CpsK.exp} \rightarrow (PP \rightarrow {\rm set} \; PP) \rightarrow (PP \rightarrow {\rm set} \; PP)$. We use the reachability analysis to compute for a given program point, which variables reach definitions in the rest of the expression to determine which variables are still live. 
\item Transform program ${\tt dupate} : {\rm CpsK.exp} \rightarrow (PP \rightarrow {\rm set} \; PP) \rightarrow {\rm Low.program}$. During lowering from a CpsK program to a Low program, we keep around a set of tuple variables in scope. When we encounter a {\tt mkTuple} operation, we check to see if there is a tuple variable in scope that is dead. If so, we perform a destructive update by reusing the dead variable instead of calling {\tt malloc}. Figures ~\ref{fig:dupdate1} ~\ref{fig:dupdate2} ~\ref{fig:dupdate3} demonstrate the results of running our optimization.
\end{itemize}

\begin{figure}
\centering
\begin{minipage}[t]{.31\textwidth}
\lstset{language=cpsk, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
let x := mkTuple(Con('S'), Con('0')) in
let y := mkTuple(Con('S'), Con('0')) in
let z := mkTuple(Con('S'), Con('0')) in
z
\end{lstlisting}
\lstset{language=low, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  halt x_1
}
\end{lstlisting}
\centering (a)
\end{minipage}
\hspace{5pt}
\begin{minipage}[t]{.31\textwidth}
\lstset{language=cpsk, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
let x := mkTuple(Con('S'), Con('O')) in
let y := mkTuple(Con('S'), Con('O')) in
let w := mkTuple(Con('S'), x) in
let z := mkTuple(Con('S'), Con('O')) in
z
\end{lstlisting}
\lstset{language=low, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  [x_2] = malloc(<int,int>)
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store x_1@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  halt x_2
}
\end{lstlisting}
\centering (b)
\end{minipage}
\hspace{5pt}
\begin{minipage}[t]{.31\textwidth}
\lstset{language=cpsk, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
let x := mkTuple(Con('S'), Con('0')) in
let y := mkTuple(Con('S'), Con('0')) in
let w := mkTuple(Con('S'), x) in
let z := mkTuple(Con('S'), Con('0')) in
w
\end{lstlisting}
\lstset{language=low, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  [x_2] = malloc(<int,int>)
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store x_1@int into x_2 + 1
  [x_4] = malloc(<int,int>)
  store Con('S')@int into x_4 + 0
  store Con('0')@int into x_4 + 1
  halt x_2
}
\end{lstlisting}
\centering (c)
\end{minipage}
\caption{In example (a), only the last variable z is used. Consequently, we can write y into x, and z into y. In example (b), we can destructively update y since y is dead. The variable y could not use x because a future program point w uses it. At program point z, w is dead, so z can update w. In example (c), we destructively updates y since y is dead. At program point z, we must allocate since both w and x are being used, and w is already using y. Note that our analysis does not remove dead values from the code, so z is still allocated in this example. }
\label{fig:dupdate}
\end{figure}

\section{Contification}
\label{sec:contification}
The current back-end stack allocates continuation environments so it is desireable to use continuations rather than full-blown, first-class, heap-allocated closures when we can do it. We have implemented contification based on Kennedy's algorithm~\cite{kennedy07cps}. Several examples of contification at work can be seen in the snippets in Figure~\ref{fig:contification}.
\begin{figure}[htb]
\centering
\begin{minipage}{0.4\textwidth}
\lstset{language=cpsk, basicstyle={\footnotesize\ttfamily}}
   \begin{lstlisting}[gobble=6,caption={Before contification}]
      let f(%c1; x_2) := 
        let x_3 := mkTuple(Con('S'),x_2) in
        return %c1(x_3) in
      let x_4 := mkTuple(Con('S'),Con('O')) in
      letK %f7(a_5) := 
        let main_6 := a_5 in
        HALT main_6 <init-world> in
      f(%f7; x_4)
    \end{lstlisting}
\end{minipage}
\begin{minipage}{0.1\textwidth}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\lstset{language=cpsk, basicstyle={\footnotesize\ttfamily}}
    \begin{lstlisting}[gobble=6,caption={After contification}]
      letK %f1(x_2) := 
        let x_3 := mkTuple(Con('S'),x_2) in
        return %f7(x_3) in
      let x_4 := mkTuple(Con('S'),Con('O')) in
      letK %f7(a_5) := 
        let main_6 := a_5 in
        HALT main_6 <init-world> in
      return %f1(x_4)
    \end{lstlisting}
\end{minipage}

%% \begin{minipage}{0.4\textwidth}
%%    \begin{lstlisting}[gobble=6,caption={Before contification}]
%%       let f(%c1; x_2) :=
%%         let x_3 := mkTuple(Con('S'),x_2) in
%%         return %c1(x_3) in
%%       let x_4 := mkTuple(Con('S'),Con('O')) in
%%       letK %f7(a_5) := 
%%         let main_6 := a_5 in
%%         HALT main_6 <init-world> in
%%       f(%f7; x_4)
%%     \end{lstlisting}
%%     \begin{lstlisting}[gobble=6,caption={After contification}]
%%       letK %f1(x_2) :=
%%         let x_3 := mkTuple(Con('S'),x_2) in
%%         return %f7(x_3) in
%%       let x_4 := mkTuple(Con('S'),Con('O')) in
%%       letK %f7(a_5) := 
%%         let main_6 := a_5 in
%%         HALT main_6 <init-world> in
%%       return %f1(x_4)
%%     \end{lstlisting}
%% \end{minipage}

\caption{Applications of contification. Note that the function \lstinline!f! is converted into a continuation since it does not escape and all of its call sites pass it the same continuation arguments.}
\label{fig:contification}
\end{figure}

The pass is similar in structure to dead-code elimination and proceeds bottom up. Escaping values (i.e. values placed in tuples or closed over by local functions) are recorded in addition to a mapping from function names to the list of continuation arguments they are applied to. At a declaration for function \lstinline!f! we can contify \lstinline!f! if it does not escape and all application occurances are applied with the same continuation arguments. 

\section*{Experiences \& The Future}
The development process in Coq has been interesting and instructive. Throughout the course of development we have noticed a number of issues that make ext-lib~\cite{coq-ext-lib} more difficult to program with than, for example, the Haskell libraries. 

The benefits to using Coq is the existance of incremental development strategies such as \coqe{refine} that allow you to see the context at any point. In addition the tight integration of the interpreter makes it reasonably easy to test code.

The cons to Coq development, however, are numerous. To be feasible for rapid development, ext-lib would require numerous changes but even with these changes it is difficult to recommend Coq as a opposed to a more traditional language. While things seem to work when they are correct, error messages for type-class resolution are either non-existant (type class resolution essentially diverges) or incredibly opaque. \coqe{refine} helps this to a limited extent. The use of the fixpoint monad (from ext-lib) drastically reduces the problem of general recursion.


We plan to make the entire repository publically avaialable on GitHub under and organization so that it has communal ownership from all of its collaborators.

%% A similar algorithm applies to recursive function declarations but we have to handle the problem of renamed continuations. We assume let-factoring (not implemented) so we only consider the problem of contifying the entire set of declarations. 


%% \section{Stack Allocation}
%% \label{sec:stack-alloc}
%% The core of the idea was presented in Kennedy~\cite{kennedy07cps}. Rather than storing everything in the heap, we'd like to stack allocate information that is accessed in a statically determinable pattern. The benefit, we hope, is that we avoid a lot of heap allocation and thus garbage collection, esspecially before we have optimizations like un-currying and partial applications that are only passed forward.

%% The use of LLVM may provide difficulties for this task since LLVM has a built-in allocation stack. When we perform this type of operation, we want to replace the current stack frame with the stack frame of the continuation and then tail call the function that we pass the continuation to but preserving the continuations environment (which just replaced our stack frame). The basic proposal for doing this is shown in Figure~\ref{fig:stack-alloc}. 

%% \begin{figure}
%% \begin{tabular}{p{0.44\textwidth} c p{0.44\textwidth}}
%% \begin{lstlisting}[language=c]
%% void f(...) { 
%%   // heap allocate the env
%%   k_env = $\langle$env$\rangle$ ;
%%   g(x, k) (** tail call g **)
%% }
%% \end{lstlisting}
%% & \quad
%% & 
%% \begin{lstlisting}[language=c]
%% void trampoline_f(...) {
%%   // using alloca
%%   k_env = $\langle$env$\rangle$ ;
%%   // non-tail call of g
%%   g(x)
%% }
%% void f(...) {
%%   // tail call g
%%   trampoline_f(...)
%% }
%% \end{lstlisting}
%% \\
%% (a) before stack allocation & &
%% (b) after stack allocation \\ 
%% \end{tabular}
%% \caption{Strategy for stack allocation of continuations.}
%% \label{fig:stack-alloc}
%% \end{figure}

%% Two alternatives to this approach are:
%% \begin{enumerate}
%% \item manually manage a separate data stack (in the style of XFI) where these operations can be performed explicitly.
%% \item write LLVM intrinsics that perform explicit stack management and implement code generation for them to get the right behavior.
%% \end{enumerate}
%% The former seems like it may be feasible, the later seems like it could require considerable work though might be interesting to understand how these things work.

%% Other potentially interesting papers:
%% \begin{itemize}
%% \item ``Contification using dominators''~\cite{fluet01contification}
%% \item ``The essence of compiling with continuations''~\cite{flanagan04essence}
%% \item ``Local CPS conversion in a direct-style compiler''~\cite{reppy01local}
%% \item ``Optimizing nested loops using local CPS conversion''~\cite{reppy02optimizing}
%% \item ``A Lambda Term Representation Inspired by Linear Ordered Logic''~\cite{abel11lambda}
%% \end{itemize}

%% \section{Garbage Collection}
%% \label{sec:gc}

\bibliographystyle{plain}
\bibliography{bib}{}

\end{document}
