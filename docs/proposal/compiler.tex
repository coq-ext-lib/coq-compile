\documentclass{article}

\usepackage{listings}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{color}
\usepackage{amsmath}
\usepackage{lstcoq}

\lstset{mathescape=true,basicstyle=\small\ttfamily,frame=lines,language=coq}

\title{cs252r: coq compilation \& runtime}
\author{Daniel Huang \and Gregory Malecha \and Scott Moore}

\newcommand{\todo}[1]{\textcolor{red}{#1}}

\begin{document}

\maketitle

Our project expanded to encompass 7 main tasks. The foremost of those is to have a working compiler, i.e. we placed a large emphasis on generating runnable LLVM code. This resulted in seven pieces:

\begin{description}
\item[Driver \& Test Tools]
We built (and refactored the previous driver) to run our compiler with a number of options, e.g. outputting intermediate representations, running and not running optimizations, etc. This makes the compiler externally usuable and facilitates testing. In addition, we have extracted an interpreter that can be used to test optimizations. (Section~\ref{sec:driver})
\item[Refactored ILs]
Our initial tasks centered around refactoring the intermediate language. In the Cps representation, we syntactically distinguished continuations and extended the IL to support monadic operations in a world-passing style. In addition, we introduced a new intermediate language (Low) that separates the details of this Cps representation from the details of code-generation. (Section~\ref{sec:il})
\item[Input/Output]
To support debugging, our runtime supports output operations to print ascii characters. These can be composed in Coq to implement displaying strings and other interesting data types. These operations are accessed via parameters exposed in Coq and compiled to special routines by our compiler. (Section~\ref{sec:io})
\item[Garbage Collection]
GC-based functional languages require a reasonable garbage collector and runtime environment. We developed a Chaney-copying collector built using LLVM's GC intrinsics. (Section~\ref{sec:gc})
\item[Abstract Interpretation] 
We built an abstract interpreter for our Cps representation to facilitate more interesting analyses. We have instantiated it to do a standard control-flow analysis though it is phrased in a way that enables it to be used for a variety of analyses. (Section~\ref{sec:abstract-interp})
\item[Destructive Updates]
A major issue with functional languages is the creation of temporary data structures. For example, threading a state through computations in the state monad. To avoid the cost of many small allocations (primarily to ease the GC burden since allocation is reasonable fast) we have an optimization that uses the result of static analysis to reuse dead memory. (Section~\ref{sec:destructive-updates})
\item[Contification]
Distinguished continutations are handled efficiently by our compiler enabling us to stack allocate data associated with continuations. An optimization works on demoting first-class functions into continuations to increase the applicability of this process. (Section~\ref{sec:contification})
\end{description}

\section{The Driver}
\label{sec:driver}

The driver is built from using standard Coq extraction to ML to provide an efficient way to run the top-level compiler. For example, we can compile and run the standard HelloWorld program using the following command line:

\begin{verbatim}
$ ./Wrapper.byte - ...
$ ./helloworld.native
Hello World!
\end{verbatim}

In in addition to the driver, we also have an interpreter for our CpsK language. The semantics are faithful to the real semantics with the exception that there is no semantic distinction between continuations and closures. The former should be not be allowed to escape. We rely on our syntactic distinction to enforce this though it may be possible to break this requirement. The interpreter can be run using:

\begin{verbatim}
$  (even 10)
$
....
\end{verbatim}

\section{Intermediate Languages}
\label{sec:il}

Our compiler is based on two core intermediate languages, CpsK and Low, both shown in Figure~\ref{fig:cpsk-low}.
\begin{figure}

TODO

\caption{}
\label{fig:cpsk-low}
\end{figure}

The motivation for Low is to provide a higher-level, but imperative language to serve as an intermediate point between CpsK and LLVM. This enables the final code generation phase to be simpler and focus more on garbage collection while avoiding the need to do large transformations to the structure of code.

Low has several interesting design decisions:
\begin{description}
\item[Functional Blocks]
\item[Explicit Memory Operations]
\item[Inline Calls]
\end{description}

\section{Input/Output}
\label{sec:io}

The compiler provides a small runtime library that enables compilation of computations that perform I/O. These operations are exposed to Coq using a simple IO mond that supports the standard \lstinline!return! and \lstinline!bind! in addition to \lstinline!printChar : ascii -> IO unit!. Extraction rules are specified for these functions and, if the program is compiled with I/O support, these functions are included by the compiler.

\lstinline!printChar! is implemented as a monadic operation in CpsK. \todo{two options for implementation}


\section{Garbage Collection}
\label{sec:gc}

Our runtime supports three basic types: \emph{integers}, \emph{pointers}, and \emph{records}. Integers have a low-order bit of one and are used to encode both constructors and machine words, though our current front-end does not emit non-constructor integers. Pointers and integers are both stored in words large enough to encode a pointer on the target architecture, and can be distinguished by their low-order bit, since objects in the runtime are at least 4-byte aligned. A record is a sequence of $n > 1$ integers or pointers preceeded by a header word indicating the length of the record. The runtime does not permit pointers into the middle of objects. As a result, headers can be stored as an integer with no tag, eliminating additional arithmetic when indexing a record.

We implemented a semispace garbage collector based on Cheney's algorithm. The source code is given in Listing~\ref{code:forward}. The collector is similar to Appel's copying collector, but is simplified by our data representation. A brief description of the algorithm follows.

\paragraph{Finding stack roots} To find the local roots from which to traverse the reachable heap, we rely on LLVM's ``shadow stack'' plugin. We emit explicit stack allocations for all local variables that may point into the heap, and mark these as roots using the \lstinline!@llvm.gcroot! intrinsic. The shadow stack plugin emits additional code during function prologues and epilogues to construct a linked list of frame maps recording the addresses of the marked roots. This entry to this linked list is accessible to the garbage collector via a global variable. There are two advantages to recording roots dynamically this way: it is highly portable, and does not require writing low-level code to walk through stack frames. On the other hand, frame maps can be computed statically and generating the shadow stack has significant overhead.

Our generated code stores heap pointers into these stack slots immediately before function calls and invocations of the garbage collector, and reloads the possibly modified pointers afterwards. As an optimization, we only store and reload roots for live variables and set roots for dead variables to null.

\paragraph{Forwarding pointers} The core of Cheney's algorithm is a routine for \emph{forwarding} pointers---copying pointed-to objects into ``tospace'' and updating pointers to the new locations. \lstinline!forward(universal_t *objref)! takes as input a pointer to a word that may itself be a pointer into the heap. If the word is not a pointer into ``fromspace'', it doesn't need to be updated. If the word is a pointer into ``fromspace'', there are two possibilites:
\begin{enumerate}
\item The pointed-to object has not been copied to ``tospace''. The object is copied into the free space at the end of ``tospace''. In ``fromspace'', the header is replaced a tag denoting that the object has been copied. We use 0 because it is an invalid record length, and header tags never need to be differentiated from pointers. A forwarding pointer to the object's new location is overwritten in the first slot of the record.
\item The pointed-to object was already copied to ``tospace''. We detect an object has already been copied by looking for the forwarding pointer tag in the header, and then update the pointer being forwarded with the forwarding pointer we stored when copying the object.
\end{enumerate}
Cheney's algorithm copies the live heap in a breadth first search from the roots. First, the roots in the shadow stack are forwarded into ``tospace'' and then objects in ``tospace'' are traversed as a queue, forwarding any pointers encountered and copying reachable objects.

\paragraph{Memory protection} To catch garbage collection errors as quickly as possible, we read and write protect the unused semispace when not actively garbage collection. This was a key debugging technique for making sure stack roots were being updated correctly.

\paragraph{Allocation} We use a bump pointer allocator for speedy allocation. Because LLVM does not support pinning global values in registers, all functions we emit take a structure containing the current base and limit pointers as an argument, and return a structure that contains a new base and limit pointer and the functions actual return value. Because these structs are ``Plain Old Data'' types, LLVM will emit code that passes these values in registers whenever possible. This has the added advantage of allowing LLVM to spill the allocator registers when doing so would result in more efficient code.

\begin{figure}
\lstset{language=C,caption={Copying collector},label={code:forward}, basicstyle={\footnotesize\ttfamily}}
\begin{lstlisting}
void forward(universal_t *objref) {
  universal_t *ptr = *((universal_t **)objref);
  if (is_ptr(ptr) && (ptr >= curbot && ptr < curtop)) {
    /* ptr is a pointer to an object in fromspace */
    if (is_rec(ptr)) {
      /* Get a pointer to the header */
      universal_t *header = hdr(ptr);
      /* Retrieve the length of the record (plus one for the header) */
      universal_t len = rec_len(ptr) + 1;
      /* Copy the object starting at the header into tosapce */
      universal_t *i = header;;
      universal_t *j = endptr;
      while (len-- > 0) {
	*j++ = *i++;
      }
      /* Set the forwarding pointer in fromspace and update the record's tag */
      *ptr = (universal_t)(endptr + 1);
      *header = UINTPTR_MAX;
      /* Move the end of the queue forward */
      endptr = j;
    }
    /* ptr must be a forwarding pointer. It either already was, or we 
       forwarded it above. Update the objref to point to the new object */
    *objref = *((universal_t *)ptr);
  }
}

void visitGCRoot(void **root, const void *meta) {
  forward((universal_t *)root);
}

bumpptr_t coq_gc(void) {
  universal_t *tospace = (curbot == tobot) ? frombot : tobot;

  /* ... omitted memory protection code ... */

  /* initialize the queue in tospace */
  queueptr = (curbot == frombot) ? tobot : frombot;
  endptr = queueptr;

  /* Call forward on the roots */
  visitGCRoots(&visitGCRoot);

  /* iterate the worklist until we're done copying */
  while (queueptr < endptr) {
    universal_t *objref = queueptr+1;
    assert(is_rec(objref)); /* all heap allocations are records */
    queueptr += rec_len(objref) + 1;
    do {
      forward(objref++);
    } while (objref < queueptr);
  }

  /* ... omitted memory protection code ... */

  /* Swap spaces and return the new bump pointers */
  curbot = (curbot == frombot) ? tobot : frombot;
  curtop = (curtop == fromtop) ? totop : fromtop;

  assert(curbot <= endptr && endptr <= curtop);

  /* allocation starts at the end of the queue */
  return (bumpptr_t) { .base = endptr, .limit = curtop };
}
\end{lstlisting}
\end{figure}

\section{Abstract Interpretation}
\label{sec:abstract-interp}

We implemented a Horn-style~\cite{van2010abstracting} abstract interpreter for the CpsK language in the sense that we tried to design our abstract interpreter so that it mirrored our concrete interpreter as much as possible. We parameterize it over an abstract domain (Figure~\ref{fig:absinterp}) so it can be instantiated with different domains for different analyses. 

\begin{figure}
\centering
\begin{minipage}[t]{.2\textwidth}
\begin{align*}
C: & \text{Context} \\
PP: & \text{Program point} \\
\hat{V}: & \text{Abstract values} \\
D: & \text{Domain}
\end{align*}
\end{minipage}
\hspace{20pt}
\begin{minipage}[t]{.43\textwidth}
\begin{lstlisting}
Class AbsDomain : Type :=
{ lookup  : C -> PP -> D -> V
; update  : C -> PP -> V -> D -> D
; joinA   : D -> D -> D
; bottomA : V 
; topA    : V 
; dom_leq : D -> D -> bool
}.
\end{lstlisting}
\end{minipage}
\caption{Select parameters of the abstract interpreter.}
\label{fig:absinterp}
\end{figure}

\begin{figure}
\begin{align*}
& p \in PP, i \in Z, c \in \text{str}, k \in \text{cont}, x \in \text{var}, e \in \text{exp}, \ell \in \text{loc} \\
C := & \;\; \text{unit} \\
PP := & \;\; \text{var} + \text{cont} \\
\hat{v} ::= & \;\; \texttt{Int}(i) \;\; | \;\; \texttt{Constructor}(c) \;\; | \;\; \texttt{Loc}(\ell) \;\; | \;\; \texttt{Closure}(p, \lambda \vec{k} \vec{x}. e) \\
\hat{V}::= & \;\; \texttt{Any} \;\; | \;\; [\hat{v}_1, \hdots, \hat{v}_n] \\
D: & \;\; \{{\tt env}: PP \rightarrow \hat{V} ; \;\;\; {\tt heap}: \text{loc} \rightarrow [\hat{V}_1, \hdots, \hat{V}_n] \}
\end{align*}
\caption{Instantiation of abstract domain for 0-CFA.}
\label{fig:cfa0}
\end{figure}
Figure~\ref{fig:cfa0} shows an instantiation of our abstract interpreter to perform a context-insensitive Control Flow Analysis (0-CFA). We treat program points as either a variable or continuation because they are uniquely named. Abstract locations are just the variable names occurring in {\tt MkTuple} declarations. The domain $D$ is a record of an environment and heap. The environment maps program points to abstract values, while the heap maps an abstract location to a list of abstract values representing the values each position of a tuple can take on. We did not put closures in the heap because we are doing a context-insensitive analysis. 

\section{Destructive Updates}
\label{sec:destructive-updates}

The main idea of a destructive update is to reuse previously allocated memory instead of allocating fresh space if we can prove that all pointers to the old memory are dead. One interesting application of this optimization is for programs that use the state monad. After an inlining pass inlines the definitions of bind to expose the state tuples explicitly, we can destructively update state that is threaded through the program instead of allocating new space for each bind. We based our optimization off the ideas described by Dimoulas and Wand in~\cite{dimoulas2009higher}, which presents an algorithm for detecting and transforming higher-order programs to use destructive updates. We summarize the optimization below. 

\begin{itemize}
\item Perform control flow analysis ${\tt cfa} : {\rm CpsK.exp} \rightarrow (PP \rightarrow \mathcal{P}(\hat{V}))$ using abstract interpretation. 
\item Perform reachability analysis ${\tt reach} : (PP \rightarrow \mathcal{P}(\hat{V})) \rightarrow (PP \rightarrow {\rm set} \; PP)$ using the result of the CFA, to compute for each program point the set of program points that flow to it (i.e., transitive closure on the domain produced by CFA).
\item Perform liveness analysis ${\tt live} : {\rm CpsK.exp} \rightarrow (PP \rightarrow {\rm set} \; PP) \rightarrow (PP \rightarrow {\rm set} \; PP)$. We use the reachability analysis to compute for a given program point, which variables reach definitions in the rest of the expression to determine which variables are still live. 
\item Transform program ${\tt dupate} : {\rm CpsK.exp} \rightarrow (PP \rightarrow {\rm set} \; PP) \rightarrow {\rm Low.program}$. During lowering from a CpsK program to a Low program, we keep around a set of tuple variables in scope. When we encounter a {\tt MkTuple} operation, we check to see if there is a tuple variable in scope that is dead. If so, we perform a destructive update by reusing the dead variable instead of calling {\tt malloc}. Figures ~\ref{fig:dupdate1} ~\ref{fig:dupdate2} ~\ref{fig:dupdate3} demonstrate the results of running our optimization.
\end{itemize}

\begin{figure}
\centering
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
let x = MkTuple('S', '0') in
let y = MkTuple('S', '0') in
let z = MkTuple('S', '0') in
z
\end{lstlisting}
\end{minipage}
\hspace{20pt}
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  halt x_1
}
\end{lstlisting}
\end{minipage}
\caption{In this example, only the last variable z is
   used. Consequently, we can write y into x, and z into y. }
\label{fig:dupdate1}
\end{figure}

\begin{figure}
\centering
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
let x = MkTuple('S', '0') in
let y = MkTuple('S', '0') in
let w = MkTuple('S', x) in
let z = MkTuple('S', '0') in
z
\end{lstlisting}
\end{minipage}
\hspace{20pt}
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  [x_2] = malloc(<int,int>)
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store x_1@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  halt x_2
}
\end{lstlisting}
\end{minipage}
\caption{In this example, w can destructively update y since y is
  dead. The variable y could not use x because a future program point
  w uses it. At program point z, w is dead, so z can update w. }
\label{fig:dupdate2}
\end{figure}

\begin{figure}
\centering
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
let x = MkTuple('S', '0') in
let y = MkTuple('S', '0') in
let w = MkTuple('S', x) in
let z = MkTuple('S', '0') in
w
\end{lstlisting}
\end{minipage}
\hspace{20pt}
\begin{minipage}[t]{.4\textwidth}
\begin{lstlisting}
coq_main() {
l1(inscope: ; args: ):
  [x_1] = malloc(<int,int>)
  store Con('S')@int into x_1 + 0
  store Con('0')@int into x_1 + 1
  [x_2] = malloc(<int,int>)
  store Con('S')@int into x_2 + 0
  store Con('0')@int into x_2 + 1
  store Con('S')@int into x_2 + 0
  store x_1@int into x_2 + 1
  [x_4] = malloc(<int,int>)
  store Con('S')@int into x_4 + 0
  store Con('0')@int into x_4 + 1
  halt x_2
}
\end{lstlisting}
\end{minipage}
\caption{In this example, w destructively updates y since y is
  dead. At program point z, we must allocate since both w and x are
  being used, and w is already using y. }
\label{fig:dupdate3}
\end{figure}

%Peforming optimizations for monadic computation will involve two
%parts. First, since our CPS representation does not contain monadic
%constructs, we need to run some sort of inference algorithm to recover
%the monadic structure. For instance, recovering the state monad
%might include running escape analysis to track the flow of function
%arguments into functions that have ``bind-like'' signatures. The
%second part will include the actual optimization once we have 
%recovered the monadic structure. For the state monad, this might
%include rewriting bind such that it does not construct a new state
%with updated values each time, but rather update the original state
%with the new values. 

%I have included a few papers that I think will be useful for me to take a
%look at
%~\cite{ghani2007monadic,pudlak2011reader,tolmach1998optimizing}, and
%would appreciate further suggestions. The
%first~\cite{ghani2007monadic}, talks about how shortcut fusion can be
%used to optimize monadic computations that only use monads to thread
%information through the program (might be useful for state, etc.). The
%second~\cite{pudlak2011reader} explains how to translate code using
%reader monads into lambda expressions that do not contain variables. The
%third~\cite{tolmach1998optimizing} describes an IR with monadic types,
%how to translate a ML-like source language into that IR, and provides
%an inference algorithm for translating terms in the ML-like source
%language into the IR. 

\section{Contification}
\label{sec:contification}

%%<<<<<<< Updated upstream
\section{Stack Allocation}
\label{sec:stack-alloc}
%% The core of the idea was presented in Kennedy~\cite{kennedy07cps}. Rather than storing everything in the heap, we'd like to stack allocate information that is accessed in a statically determinable pattern. The benefit, we hope, is that we avoid a lot of heap allocation and thus garbage collection, esspecially before we have optimizations like un-currying and partial applications that are only passed forward.

%% The use of LLVM may provide difficulties for this task since LLVM has a built-in allocation stack. When we perform this type of operation, we want to replace the current stack frame with the stack frame of the continuation and then tail call the function that we pass the continuation to but preserving the continuations environment (which just replaced our stack frame). The basic proposal for doing this is shown in Figure~\ref{fig:stack-alloc}. 

%% =======
The current back-end stack allocates continuation environments so it is desireable to use continuations rather than full-blown, first-class, heap-allocated closures when we can do it. We have implemented contification based on Kennedy's algorithm~\cite{kennedy07cps}. Several examples of contification at work can be seen in the snippets in Figure~\ref{fig:contification}.
%%>>>>>>> Stashed changes
\begin{figure}

   \begin{lstlisting}[gobble=6,caption={Before contification}]
      let f(%c1; x_2) := 
        let x_3 := mkTuple(Con('S'),x_2) in
        return %c1(x_3) in
      let x_4 := mkTuple(Con('S'),Con('O')) in
      letK %f7(a_5) := 
        let main_6 := a_5 in
        HALT main_6 <init-world> in
      f(%f7; x_4)
    \end{lstlisting}
    \begin{lstlisting}[gobble=6,caption={After contification}]
      letK %f1(x_2) := 
        let x_3 := mkTuple(Con('S'),x_2) in
        return %f7(x_3) in
      let x_4 := mkTuple(Con('S'),Con('O')) in
      letK %f7(a_5) := 
        let main_6 := a_5 in
        HALT main_6 <init-world> in
      return %f1(x_4)
    \end{lstlisting}

\caption{Applications of contification. Note that the function \lstinline!f! is converted into a continuation since it does not escape and all of its call sites pass it the same continuation arguments.}
\label{fig:contification}
\end{figure}

The pass is similar in structure to dead-code elimination and proceeds bottom up. Escaping values (i.e. values placed in tuples or closed over by local functions) are recorded in addition to a mapping from function names to the list of continuation arguments they are applied to. At a declaration for function \lstinline!f! we can contify \lstinline!f! if it does not escape and all application occurances are applied with the same continuation arguments. 

A similar algorithm applies to recursive function declarations though we have not implemented it. The difficulty is the same as the difficulty of factoring recursive \lstinline!let! declarations, we need to construct a graph of dependencies 


%% \section{Stack Allocation}
%% \label{sec:stack-alloc}
%% The core of the idea was presented in Kennedy~\cite{kennedy07cps}. Rather than storing everything in the heap, we'd like to stack allocate information that is accessed in a statically determinable pattern. The benefit, we hope, is that we avoid a lot of heap allocation and thus garbage collection, esspecially before we have optimizations like un-currying and partial applications that are only passed forward.

%% The use of LLVM may provide difficulties for this task since LLVM has a built-in allocation stack. When we perform this type of operation, we want to replace the current stack frame with the stack frame of the continuation and then tail call the function that we pass the continuation to but preserving the continuations environment (which just replaced our stack frame). The basic proposal for doing this is shown in Figure~\ref{fig:stack-alloc}. 

%% \begin{figure}
%% \begin{tabular}{p{0.44\textwidth} c p{0.44\textwidth}}
%% \begin{lstlisting}[language=c]
%% void f(...) { 
%%   // heap allocate the env
%%   k_env = $\langle$env$\rangle$ ;
%%   g(x, k) (** tail call g **)
%% }
%% \end{lstlisting}
%% & \quad
%% & 
%% \begin{lstlisting}[language=c]
%% void trampoline_f(...) {
%%   // using alloca
%%   k_env = $\langle$env$\rangle$ ;
%%   // non-tail call of g
%%   g(x)
%% }
%% void f(...) {
%%   // tail call g
%%   trampoline_f(...)
%% }
%% \end{lstlisting}
%% \\
%% (a) before stack allocation & &
%% (b) after stack allocation \\ 
%% \end{tabular}
%% \caption{Strategy for stack allocation of continuations.}
%% \label{fig:stack-alloc}
%% \end{figure}

%% Two alternatives to this approach are:
%% \begin{enumerate}
%% \item manually manage a separate data stack (in the style of XFI) where these operations can be performed explicitly.
%% \item write LLVM intrinsics that perform explicit stack management and implement code generation for them to get the right behavior.
%% \end{enumerate}
%% The former seems like it may be feasible, the later seems like it could require considerable work though might be interesting to understand how these things work.

%% Other potentially interesting papers:
%% \begin{itemize}
%% \item ``Contification using dominators''~\cite{fluet01contification}
%% \item ``The essence of compiling with continuations''~\cite{flanagan04essence}
%% \item ``Local CPS conversion in a direct-style compiler''~\cite{reppy01local}
%% \item ``Optimizing nested loops using local CPS conversion''~\cite{reppy02optimizing}
%% \item ``A Lambda Term Representation Inspired by Linear Ordered Logic''~\cite{abel11lambda}
%% \end{itemize}

%% \section{Garbage Collection}
%% \label{sec:gc}

\bibliographystyle{natbib}
\bibliography{bib}{}

\end{document}
