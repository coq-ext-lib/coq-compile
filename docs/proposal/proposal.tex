\documentclass{article}

\usepackage{listings}
\usepackage{fullpage}
\usepackage{hyperref}

\lstset{mathescape=true,basicstyle=\small,frame=lines}

\title{cs252r: coq compilation \& runtime}
\author{Daniel Huang \and Gregory Malecha \and Scott Moore}

\begin{document}

\maketitle

Our proposal is a somewhat combined project that focuses on the back-end of the compilation process and its interface with the run time system. There are three primary components to it:

\begin{description}
\item[Monadic Computation] I plan to work on monadic optimizations,
  focusing particularly on reader, writer and state. (Dan, see Section~\ref{sec:mon-com})
\item[Stack Allocation] I'll look into how to to stack allocation continuations and data. The hope is that stack allocation provides a nice place to store extra data for the monadic optimizations that the monadic computation will work on and require negotiations with the garbage collection, described next (Gregory, see Section~\ref{sec:stack-alloc})
\item[Garbage Collection] I'll write a garbage collector for our runtime. The initial goal will be to get a simple collector in place for other groups to run their code against. I'll also refactor the bitcode generation phase to abstract the runtime further and give primitives for things like stack allocation. Once this is done, I will investigate more sophisticated garbage collection algorithms. The hope is that compiling a highly-pure language will allow for the \emph{relatively} simple implementation of a concurrent or parallel collector. (Scott, see Section~\ref{sec:gc})
\end{description} 

Because these projects are all closely tied to the backend, i.e. both stack allocation and monadic optimization require communicating interesting information to the garbage collector, we believe that these projects are best done with close collaboration.

\section{Monadic Computation}
\label{sec:mon-com}

Peforming optimizations for monadic computation will involve two
parts. First, since our CPS representation does not contain monadic
constructs, we need to run some sort of inference algorithm to recover
the monadic structure. For instance, recovering the state monad
might include running escape analysis to track the flow of function
arguments into functions that have ``bind-like'' signatures. The
second part will include the actual optimization once we have 
recovered the monadic structure. For the state monad, this might
include rewriting bind such that it does not construct a new state
with updated values each time, but rather update the original state
with the new values. 

I have included a few papers that I think will be useful for me to take a
look at
~\cite{ghani2007monadic,pudlak2011reader,tolmach1998optimizing}, and
would appreciate further suggestions. The
first~\cite{ghani2007monadic}, talks about how shortcut fusion can be
used to optimize monadic computations that only use monads to thread
information through the program (might be useful for state, etc.). The
second~\cite{pudlak2011reader} explains how to translate code using
reader monads into lambda expressions that do not contain variables. The
third~\cite{tolmach1998optimizing} describes an IR with monadic types,
how to translate a ML-like source language into that IR, and provides
an inference algorithm for translating terms in the ML-like source
language into the IR. 

\section{Stack Allocation}
\label{sec:stack-alloc}
The core of the idea was presented in Kennedy~\cite{kennedy07cps}. Rather than storing everything in the heap, we'd like to stack allocate information that is accessed in a statically determinable pattern. The benefit, we hope, is that we avoid a lot of heap allocation and thus garbage collection, esspecially before we have optimizations like un-currying and partial applications that are only passed forward.

The use of LLVM may provide difficulties for this task since LLVM has a built-in allocation stack. When we perform this type of operation, we want to replace the current stack frame with the stack frame of the continuation and then tail call the function that we pass the continuation to but preserving the continuations environment (which just replaced our stack frame). The basic proposal for doing this is shown in Figure~\ref{fig:stack-alloc}. 

\begin{figure}
\begin{tabular}{p{0.44\textwidth} c p{0.44\textwidth}}
\begin{lstlisting}[language=c]
void f(...) { 
  // heap allocate the env
  k_env = $\langle$env$\rangle$ ;
  g(x, k) (** tail call g **)
}
\end{lstlisting}
& \quad
& 
\begin{lstlisting}[language=c]
void trampoline_f(...) {
  // using alloca
  k_env = $\langle$env$\rangle$ ;
  // non-tail call of g
  g(x)
}
void f(...) {
  // tail call g
  trampoline_f(...)
}
\end{lstlisting}
\\
(a) before stack allocation & &
(b) after stack allocation \\ 
\end{tabular}
\caption{Strategy for stack allocation of continuations.}
\label{fig:stack-alloc}
\end{figure}

Two alternatives to this approach are:
\begin{enumerate}
\item manually manage a separate data stack (in the style of XFI) where these operations can be performed explicitly.
\item write LLVM intrinsics that perform explicit stack management and implement code generation for them to get the right behavior.
\end{enumerate}
The former seems like it may be feasible, the later seems like it could require considerable work though might be interesting to understand how these things work.

Other potentially interesting papers:
\begin{itemize}
\item ``Contification using dominators''~\cite{fluet01contification}
\item ``The essence of compiling with continuations''~\cite{flanagan04essence}
\item ``Local CPS conversion in a direct-style compiler''~\cite{reppy01local}
\item ``Optimizing nested loops using local CPS conversion''~\cite{reppy02optimizing}
\item ``A Lambda Term Representation Inspired by Linear Ordered Logic''~\cite{abel11lambda}
\end{itemize}

\section{Garbage Collection}
\label{sec:gc}
The first phase of the project will be to implement a simple semispace collector \`a la Cheney's algorithm. Part of this initial effort will be abstracting the code generation phase in the Coq part of the compiler to allow more flexibility during the LLVM codegen and runtime.

The second phase of the project will be to implement a more sophisticated garbage collection algorithm. This algorithm could be \emph{concurrent} or \emph{parallel} or both. A concurrent collector would be appealing to gain parallelism even though our underlying language is sequential (at least our current implementation). Even in a non-concurrent setting, a parallel collector would improve our throughput and latency. In either case, we would probably use two generations, reusing the semispace collector for the young generation.

A quick literature search shows there is some existing work on implementing concurrent or parallel collectors for functional langauges:
\begin{itemize}
\item In Haskell: ``Parallel Generational-Copying Garbage Collection with a Block-Structured Heap''~\cite{marlow:parallel}
\item In ML: ``Very Concurrent Mark-\&-Sweep Garbage Collection without Fine-Grain Synchronization''~\cite{Huelsbergen}
\item ``The Garbage Collection Handbook''~\cite{gcbook} provides a comprehensive overview of possible approaches and implementation issues.
\end{itemize}

My hope is that some of these implementation issues are mitigated by our purely-functional setting.

\bibliographystyle{natbib}

\bibliography{bib}

\end{document}
